{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/docs/user_guide/index.html"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "jupyter nbextension enable --py widgetsnbextension          # https://stackoverflow.com/a/57343401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "83437d3e-469a-4388-9376-c41ae9e59625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b48ff079-86e4-4269-9e7b-16b34a1a73f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series from list (no index)\n",
    "\n",
    "pd.Series()\n",
    "# series from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "\n",
    "# dataframe from dict\n",
    "df = pd.DataFrame({\"first\": {\"a\": 1, \"b\": 2}, \"second\": {\"a\": 1, \"b\": 3}})\n",
    "\n",
    "# from list of lists\n",
    "row_list = ([pack_PN,\n",
    "             pack_size,\n",
    "             comp_module_SN,\n",
    "             dt.datetime.strftime(Vehicle_i.get_scan_date(), DATE_FORMAT_2)])\n",
    "assoc_df = pd.DataFrame(row_list, columns=[\"Batt Assy/Mod P/N\",\n",
    "                                           \"Pack Size\",\n",
    "                                           \"Composite S/N\",\n",
    "                                           \"Vehicle last-scan date\"])\n",
    "\n",
    "# dataframe from list of pd.Series objects (all_cpf_extracts)\n",
    "pd.DataFrame(all_cpf_extracts)\n",
    "\n",
    "# dataframe from CSV\n",
    "pokemon_filepath = os.path.join(NOTEBOOK_DIR, \"reference_data\", \"pokemon.csv\")\n",
    "pokemon_df = pd.read_csv(pokemon_filepath)\n",
    "\n",
    "# dataframe from Excel\n",
    "df = pd.read_excel(file_path, index_col=1, header=None, skiprows=[0,1], na_values=pd.NA)\n",
    "raw_df = pd.read_excel(file_path, sheet_name=\"Parameters\", engine='openpyxl', header=None, dtype=str)\n",
    "faults_table = pd.read_excel(file_path, sheet_name=\"Faults\", engine='openpyxl', dtype=str)\n",
    "pd.read_excel(file_path, index_col=0, na_values=\"\", usecols=\"B,C\")\n",
    "\n",
    "# dataframe from html table\n",
    "query_url = (\"http://%s/quality/builddata?excel&Data=%s&DataTs%%5Bfrom%%5D=%s&DataTs%%5Bto%%5D=%s\"\n",
    "                                % (MES_IP, \"695788*\", start_date, end_date))\n",
    "table_dfs = pd.read_html(data_source, index_col=0, header=0, parse_dates=[\"Timestamp\"], date_format=\"%Y-%m-%d\", converters=str_cols)\n",
    "table_df = table_dfs[0].dropna(how='all')\n",
    "\n",
    "# Convert 1-column dataframe into a series\n",
    "my_series = pd.read_csv(filepath, usecols=[\"Col8\"]).squeeze(\"columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataframe - MES batt scans\n",
    "data_source = os.path.join(NOTEBOOK_DIR, \"reference_data\", \"\") #    TODO        \n",
    "table_df_raw = pd.read_html(data_source, index_col=0, header=0, parse_dates=[\"Timestamp\"], converters=str_cols)[0].dropna(how='all')\n",
    "\n",
    "# Remove rows w/ a Task Status of FAIL.\n",
    "fail_status_filter = (table_df_raw[\"Task Status\"].str.upper() == \"FAIL\")\n",
    "table_df = table_df_raw.drop(table_df_raw.loc[fail_status_filter].index)\n",
    "# Remove rows w/ blank field in Model or Part # column.\n",
    "table_df.dropna(subset=[\"Model\", \"Part #\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "056165d9-e8f1-4e9a-b357-d3f57affb92c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Getting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily allow display of full (or different number of) df contents.\n",
    "# with pd.option_context('display.max_rows', 50, 'display.max_columns', 10):\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count([\"col5\"]) # returns how many non-null vals exist in col5\n",
    "df.size([\"col5\"]) # returns how many elements exist in col5 (includes null)\n",
    "\n",
    "df.info()\n",
    "df[\"col5\"].describe() # displays various statistics and info for col5\n",
    "\n",
    "df[\"col5\"].value_counts() # provides how many times each unique value occurs in the column\n",
    "                           # row enumeration/horizontal data format ts\n",
    "df[\"col5\"].value_counts(normalize=True) # provides their relative frequency (yielding distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to access elements of a series\n",
    "\n",
    "# Get value at series index value\n",
    "myseries.loc[\"index9\"]\n",
    "myseries.get(\"index9\") # Returns None if index9 doesn't exist\n",
    "myseries.get(\"index9\", \"Nay\") # Returns \"Nay\" if index9 doesn't exist\n",
    "myseries.get([\"index8\", \"index9\"], \"One of the vals not found\")\n",
    "\n",
    "# How to return a slice of a series (by index value)\n",
    "\n",
    "# Boolean filter indicating elements in \"Menu 4\" column containing \"Fault Code \" string. If element is NA instead of a string, treat that as False.\n",
    "fault_code_filter = menu_df[\"Menu 4\"].str.contains(\"Fault Code \", na=False)\n",
    "\n",
    "# How to return a slice of a series (by index position)\n",
    "\n",
    "# How to logically filter/select (return logical/boolean series)\n",
    "# How to return index values corresponding to logical filter on index values\n",
    "# How to return index values corresponding to logical filter on series values\n",
    "\n",
    "# Look for column name in columns\n",
    "(column_name in sysinfo_df.columns)\n",
    "\n",
    "# Look for a value in a column\n",
    "(\"BMS Data\" in menu_df[\"Menu 2\"].values)\n",
    "\n",
    "# How to return a single value\n",
    "\n",
    "raw_df[\"column3\"] # return column\n",
    "raw_df.loc[\"index5\"] # returns row at index value \"index5\"\n",
    "raw_df.iloc[2] # returns row at index position 2\n",
    "\n",
    "# This returns a new dataframe (not a view)\n",
    "mydf[[\"Name\", \"Team\", \"Date\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "\n",
    "# logical slicing\n",
    "    # by rows\n",
    "    # by columns\n",
    "\n",
    "# Return rows where \"BSN\" column matches vehicle_sn string\n",
    "scan_df[scan_df[\"BSN\"]==vehicle_sn]\n",
    "\n",
    "# Return rows where value in \"Data\" col contains cell_mod_sn string\n",
    "scan_df[scan_df[\"Data\"].str.contains(cell_mod_sn)]\n",
    "\n",
    "scan_df[ (scan_df[\"BSN\"]==comp_mod_sn)\n",
    "        | (scan_df[\"Data\"].str.contains(comp_mod_sn))] # MUST USE PARENTHESES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display set of all values for each column\n",
    "for col in BDXDB.get_full_df().columns:\n",
    "    print(col, end=\":\\t\")\n",
    "    try:\n",
    "        print(sorted(list(set(BDXDB.get_full_df()[col].values))))\n",
    "    except TypeError:\n",
    "        print(list(set(BDXDB.get_full_df()[col].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding data\n",
    "\n",
    "# reorder columns\n",
    "first_cols = [\"Battery(BMS)_Bar_Code\", \"Cell_Module1_Bar_Code\", \"Cell_Module2_Bar_Code\", \"Cell_Module3_Bar_Code\"]\n",
    "raw_df = raw_df[first_cols + [c for c in raw_df.columns if c not in first_cols]]\n",
    "\n",
    "# Rename columns\n",
    "column_mapping_dict = {\"Model\": \"Model Number\",\n",
    "                       \"HW Version\": \"Hardware Version\"}\n",
    "sysinfo_df.rename(columns=column_mapping_dict, inplace=True)\n",
    "\n",
    "# Concatenating rows\n",
    "    # How index handled\n",
    "    # How duplicate index values handled\n",
    "full_df = pd.concat(list_of_dfs) # How does this work?\n",
    "\n",
    "complete_df = pd.concat([complete_df, CellExport.get_table_df()], ignore_index=True)\n",
    "\n",
    "# join\n",
    "    # inner, outer, left right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to modify values in-place\n",
    "\n",
    "table_df[\"col3\"].iloc[[1, 3, 6]] = [\"Fire\", \"Air\", \"Water\"]\n",
    "table_df[\"col3\"].loc[[\"idx1\", \"idx3\", \"idx8\"]] = [\"Fire\", \"Air\", \"Water\"]\n",
    "\n",
    "myfilter = table_df[\"col3\"].str.contains(\"replace_me\")\n",
    "table_df[\"col3\"].loc[myfilter] = [\"Fire\", \"Air\", \"Water\"]\n",
    "\n",
    "# Modify values in a column by applying some function to them\n",
    "table_df[\"GET_Date\"] = table_df[\"GET_Date\"].apply(convert_excel_date)\n",
    "\n",
    "# Round decimal places to 1 and 3\n",
    "full_df = full_df.round({\"Cruising_Speed_mph\": 1,\n",
    "                         \"BMS_Batt_State_of_Health\": 3})\n",
    "\n",
    "# Replace all of some value w/ another\n",
    "menu_df = menu_df.replace({\"Encender\": \"On\", \"Apagar\": \"Off\"})\n",
    "# Convert to boolean\n",
    "menu_df.replace({\"On\": True, \"Off\": False})\n",
    "\n",
    "# create new column\n",
    "    # apply function to an existing column's values and add as new column.\n",
    "full_df[\"Ctrl_Mfg_Date_Code\"] = pd.to_datetime(full_df[\"Ctrl_Mfg_Date_Code_Julian\"], format=\"%y%j\", errors=\"coerce\")\n",
    "full_df[\"BMS_Batt_State_of_Health\"] = full_df[\"BMS_Current_Ah_Capacity\"] / full_df[\"BMS_Ideal_Ah_Capacity\"]\n",
    "full_df[\"new_col\"] = 56 # value to put in each entry of column\"\n",
    "full_df.insert(loc=6, column=\"new_col_name\", value=SeriesOrSingleValueToInsertAsNewCol) # put column in specific place in column order (put in position 6)\n",
    "\n",
    "# Make a column into the index\n",
    "raw_df.set_index(\"column9\") # Changes column 9 to the index\n",
    "\n",
    "# Sort\n",
    "cell_df_raw.sort_values(by=\"Timestamp\", inplace=True)\n",
    "assoc_df.sort_values([\"Vehicle last-scan date\", \"Vehicle S/N\"], ascending=[True, True], ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     fire\n",
       "1     fire\n",
       "2    water\n",
       "3      NaN\n",
       "Name: col2, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = pd.DataFrame({\"col1\": [\"item1\", \"item2\", \"item3\", \"item6\"], \"col2\": [1, 2, 3, 4]})\n",
    "mapping = {1: \"fire\", 2: \"fire\", 3: \"water\", 5: \"earth\"}\n",
    "mydf[\"col2\"].map(mapping) # will map all keys to vals. Where the value at a certain \n",
    "                          # row doesn't match any of the dict keys, it will map to NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.mask()\n",
    "# df.filter()\n",
    "\n",
    "employees[employees[\"Start Date\"] > \"1985-03-01\"] # Comparing this string to series of datetime objects works right\n",
    "employees[employees[\"Last Login Time\"] < dt.time(12,0,0)]\n",
    "\n",
    "employees[\"Team\"].isin([\"Legal\", \"Sales\", \"Product\"]) # creates logical series based on whether each entry in Team column is one of the list items.\n",
    "\n",
    "employees[\"Salary\"].between(60000, 70000) # Inclusive. Equivalent to two booleans\n",
    "employees[\"Last Login Time\"].between(dt.time(8, 30), dt.time(12, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nullify bad data\n",
    "\n",
    "# Find any nulls\n",
    "any(mydf[\"col3\"].isna()) # .isna() is same as .isnull()\n",
    "mydf[\"col3\"].notnull() # True/False vector where valid values exist.\n",
    "mydf[\"col3\"][mydf[\"col3\"].notnull()] # Column with all the valid data (may be shorter)\n",
    "\n",
    "# Change any (0, 0) GPS coordinates to NULL.\n",
    "bad_gps_filter = (  (self.table_df[\"Location_Latitude\"] == 0)\n",
    "                  & (table_df[\"Location_Longitude\"] == 0)    )\n",
    "table_df.loc[bad_gps_filter, [\"Location_Latitude\", \"Location_Longitude\"]] = pd.NA\n",
    "\n",
    "bad_current_Ah_cap_filter = (   (self.table_df[\"Batt_State_of_Health\"] > 1)\n",
    "                              | (self.table_df[\"Batt_State_of_Health\"] < 0.6) )\n",
    "table_df.loc[bad_current_Ah_cap_filter, \"Current_A-h_capacity\"] = pd.NA\n",
    "\n",
    "bad_current_Ah_cap_filter = ( (self.full_df[\"BMS_F/W_Version\"] < 0.7)\n",
    "                              & ((self.full_df[\"BMS_Batt_State_of_Health\"] > 1)\n",
    "                                   | (self.full_df[\"BMS_Batt_State_of_Health\"] < 0.6)))\n",
    "full_df.loc[bad_current_Ah_cap_filter, \"BMS_Current_Ah_Capacity\"] = pd.NA\n",
    "\n",
    "# Replace the 0s w/ NA in column \"col5\" only where that row also matches fault_code_filter\n",
    "menu_df.loc[fault_code_filter, \"col5\"] = menu_df.loc[fault_code_filter, \"col5\"].replace({\"0\": pd.NA})\n",
    "\n",
    "# Remove rows w/ NA index\n",
    "mydf = mydf.loc[mydf.index.dropna()]\n",
    "\n",
    "# Remove rows w/ a Task Status of FAIL.\n",
    "fail_status_filter = (table_df[\"Task Status\"].str.upper() == \"FAIL\")\n",
    "table_df = table_df.drop(table_df.loc[fail_status_filter].index)\n",
    "\n",
    "# Remove rows w/ blank field in Model or Part # column.\n",
    "table_df.dropna(subset=[\"Model\", \"Part #\"], inplace=True)\n",
    "\n",
    "# Remove rows where BSN and Data columns both contain a comp-module P/N.\n",
    "#    Filter identifies rows where the BSN col's extracted S/N is a Batt Pack\n",
    "#    and Data column's extracted S/N starts w/ \"SV33\" (comp-module S/N).\n",
    "comp_scan_filter = (  table_df[\"BSN\"].apply(get_sn_in_bsn_col).apply(lambda BSN_Obj: isinstance(BSN_Obj, BattPack))\n",
    "                    & table_df[\"Data\"].apply(get_sn_in_data_col).apply(lambda sn_str: sn_str.startswith(COMP_SN_PREFIX))   )\n",
    "table_df.drop(table_df.loc[comp_scan_filter].index, inplace=True)\n",
    "\n",
    "# handling missing data\n",
    "    # replace NaNs (df.fillna())\n",
    "    # .dropna()\n",
    "\n",
    "raw_df.info()\n",
    "raw_df.isna().sum()\n",
    "raw_df.replace({None: pd.NA})\n",
    "import missingno as msno\n",
    "msno.matrix(df) # Shows where values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "\n",
    "# show all datatypes\n",
    "full_df.dtypes\n",
    "full_df.iloc[:, 0:10].dtypes\n",
    "\n",
    "\n",
    "# assigning type to a column's data\n",
    "raw_df.astype({\"Location_Latitude\": \"Float64\",\n",
    "               \"Min_Cell_Voltage\": \"Int64\",\n",
    "               \"GPS_Support_Enable\": \"bool\",\n",
    "               \"Export_Date\": \"datetime64[ns]\"})\n",
    "raw_df.astype({\"Fault_Code_%d\" % (n+1): \"Int64\" for n in range(10)})\n",
    "\n",
    "mydf[\"Date_col\"] = pd.to_datetime(mydf[\"Date_col\"], format=\"%Y-%m-%d\")\n",
    "# Separate time out:\n",
    "mydf[\"Time_str_col\"] = pd.to_datetime(mydf[\"Time_str_col\"], format=\"%H:%M %p\").dt.time\n",
    "\n",
    "# Category\n",
    "employees[\"Gender\"] = employees[\"Gender\"].astype(\"category\") # more efficient storage (and lookup?) than storing a bunch of \"Male\" and \"Female\" strings.\n",
    "# Use when you have a small number of unique vals in a large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export and Plotting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out to Excel\n",
    "assoc_df.to_excel(export_path, index=False, freeze_panes=(1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "\n",
    "# Series\n",
    "\n",
    "# Dataframe\n",
    "\n",
    "# X-Y plot\n",
    "# time-series plot (plotting vs. index)\n",
    "\n",
    "# Geospatial heatmap (df columns \"Location_Latitude\" and \"Location_Longitude\")\n",
    "import plotly_express as px\n",
    "fig = px.density_mapbox(full_df, lat=\"Location_Latitude\", lon=\"Location_Longitude\", radius=10, center=dict(lat=BDXDB.get_full_df()[\"Location_Latitude\"].mean(), lon=BDXDB.get_full_df()[\"Location_Longitude\"].mean()), zoom=4, mapbox_style=\"open-street-map\", height=900)\n",
    "fig.update_layout(template=\"plotly_dark\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3902567463903651,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "gen2Li_FSB_field-export_db_JDB",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
